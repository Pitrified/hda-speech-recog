% !TEX root = report.tex

\section{Processing Pipeline}
\label{sec:processing_architecture}

High level descripion of the processing flow:

Throughout the report: extract Spectrograms, classify image.

\section{Signals and Features}
\label{sec:model}

\subsection{Google Dataset}

% Measurement setup, data preprocess (describe the google dataset)

The Speech Commands datasets, described in \cite{warden2018speech}, provides thousands of one second recording of 35 words.
The recordings are mainly of volounteers, who used their own device to record the words in a closed room wherever they happened to be (not in a studio setting), and ideally each volounteer only recorded the 135 requested utterances once, so the dataset provides good variability of voices and background noises.
The utterances have a duration of one second.
To more precisely align the recorded clips, the audio was acquired for $1.5$ seconds and the 1 second clip that contained the highest overrall volume was extracted.
Several background noise recording are included as well.
The full dataset includes $105829$ utterances of $35$ words, saved in \textit{.wav} format at $16$ KHz rate.
The dataset is released under the Creative Commons BY 4.0 License \cite{ccby4}.

% TODO Train/validation/test

\subsection{Spectrograms}

Feature vectors: mel/mfcc

\subsection{Data augmentation}

\subsubsection{Time shift}

\subsubsection{Time stretch}

\subsubsection{Spectrogram warp}

\section{Learning Framework}
\label{sec:learning_framework}

How did it learn anything at all?

\subsection{Learning rate schedule}

\subsection{Hyper-parameter tuning}

\section{Convolutional Architecture}
\label{sec:convolutional_arch}

\section{Transfer Learning approach}
\label{sec:transfer_learning}

\section{Attention Model}
\label{sec:attention_model}

\subsection{Attention architecture}

\subsection{Query style}
