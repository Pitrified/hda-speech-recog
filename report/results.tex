% !TEX root = report.tex

\section{Results}
\label{sec:results}
% Dazzling numerical results

\subsection{Attention weights}

\subsubsection{Attention model}

Show attention weights for Att model

\subsubsection{AreaNet}

Show AreaNet

Show VerticalAreaNet

\subsection{Hyper-parameter analysis: CNN}

% \subsection{Hyper-parameter analysis}
% Hypa comparison
% First specific hypas

Tell total number of experiment per type

\subsection{Hyper-parameter analysis: Transfer}

\subsection{Hyper-parameter analysis: Attention}

Group by (conv, dropout, kernel, lstm, dense) to show difference in architecture

Group by query

Group by (lr, batch, epoch)

Group by dataset: not augmented, augmented

Group by type of augmentation: along both, one, none axis

Group by dataset: 1 sec vs loud section

\subsection{Architecture comparison}

Show best and top 5 average

Then aggregate table for cross architecture

Pick the best 5 models per category

Compare: CNN, Dense, Xception, EfficientB047, AreaNet, SimpleNet,
VerticalAreaNet on num, all, LTnum, LTall, numLS, allLS

Not every combination of everything

Show confusion matrices, speak about similar sounding words, note how AreaNet
does not miss them

\subsection{Stream predictions}

Compare normal vs loud

Attention vs Simple vs AreaNet vs VerticalAreaNet

Compare inference time, model size
