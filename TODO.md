# TODOs

### Misc

* Nel paper di Xception ti dicono che parametri usare per gli optimizer

* Check fscore in CNN: when doing evaluate precision/recall are at 95 then fscore is 87

* Add silence and unknown labels to learn

* https://www.pyimagesearch.com/faqs/single-faq/how-do-i-reference-or-cite-one-of-your-blog-posts-books-or-courses/

* Top one error as metric (described in the Google dataset paper)

* Mode data augmentation, mask, only roll, only stratch...

* All the documentation

### Transfer learning

* Use different base models in TRA

### Data augmentation

* https://github.com/pyyush/SpecAugment/blob/master/augment.py
* https://www.kaggle.com/CVxTz/audio-data-augmentation/notebook#Data-augmentation-definition-:

### Learning rate schedule

Function callback:

* https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler
* The func might take more inputs, use partial to do hypa tune on it

ReduceLROnPlateau:

* https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau

Cyclic learning rate:

* https://github.com/JonnoFTW/keras_find_lr_on_plateau
* https://github.com/bckenstler/CLR/blob/master/clr_callback.py
* https://www.pyimagesearch.com/2019/07/29/cyclical-learning-rates-with-keras-and-deep-learning/

* https://www.pyimagesearch.com/2019/07/22/keras-learning-rate-schedules-and-decay/
